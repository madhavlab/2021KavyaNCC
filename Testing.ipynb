{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start=time.time()\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "import scipy\n",
    "import sys\n",
    "import csv\n",
    "import itertools\n",
    "import librosa as lb\n",
    "import librosa.display\n",
    "from scipy.fftpack import dct\n",
    "from scipy.signal import argrelextrema\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "import tensorflow as tf\n",
    "from IPython.display import Audio\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the parameters\n",
    "\n",
    "fs=12800 # 12800 Sampling Fequency\n",
    "fmin=50 # Minimum frequency choosen \n",
    "B=36     # Number of bins per octave\n",
    "k1=0     # Smallest bin corresponding to 50Hz(fmin)\n",
    "k2=B*np.log2(1500/fmin)# Largest bin corresponding to 1500Hz(fmax)\n",
    "k2=int(np.ceil(k2))\n",
    "Nf=int(B*np.log2(fs/(2*fmin))) # Total number of bins in CQT\n",
    "Top=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw Pitch Accuracy\n",
    "def RPA(v,pred_Melody,pitch_labels,Nt):\n",
    "    N=0\n",
    "    D=0\n",
    "    for i in range(Nt):\n",
    "        if v[i]==1:\n",
    "            if pred_Melody[i]!=0:\n",
    "                N+=v[i]*Thres(M(pred_Melody[i])-M(pitch_labels[i]))\n",
    "            D+=v[i]\n",
    "    Raw_pitch_acc=(N/D)*100\n",
    "    #print(\"RPA is {} %\".format(Raw_pitch_acc))\n",
    "    return Raw_pitch_acc\n",
    "\n",
    "# Raw Chroma Accuracy\n",
    "def RCA(v,pred_Melody,pitch_labels,Nt):\n",
    "    N=0\n",
    "    D=0\n",
    "    for i in range(Nt):\n",
    "        if v[i]==1:\n",
    "            if pred_Melody[i]!=0:\n",
    "                N+=v[i]*Thres(Angular(M(pred_Melody[i])-M(pitch_labels[i])))\n",
    "            D+=v [i]\n",
    "    Raw_chroma_acc=(N/D)*100\n",
    "    #print(\"RCA is {} %\".format(Raw_chroma_acc))\n",
    "    return Raw_chroma_acc\n",
    "\n",
    "\n",
    "def Peak(magCQT,Nt):  # Nt is time frames\n",
    "    Peaks=np.zeros((k2+1,Nt))\n",
    "    Top_10Fo=np.zeros((Top,Nt))\n",
    "    for frame in range(Nt):\n",
    "        Row=scipy.signal.find_peaks(magCQT[k1:k2+1,frame])[0]\n",
    "        for i in range(len(Row)):\n",
    "            Peaks[Row[i]][frame]=magCQT[Row[i]][frame]\n",
    "    Sort=np.argsort(Peaks,axis=0)\n",
    "    Peaks1=np.zeros((k2+1,Nt))\n",
    "    for i in range(Nt):\n",
    "        arr=Sort[k2+1-int(Top/2):,i]\n",
    "        ind=arr[Peaks[arr,i]!=0]\n",
    "\n",
    "        for j in ind:\n",
    "            Peaks1[j][i]=magCQT[j][i]\n",
    "            Peaks1[j+1][i]=magCQT[j+1][i]\n",
    "            Peaks1[j-1][i]=magCQT[j-1][i]\n",
    "    Sort=np.argsort(Peaks1,axis=0)\n",
    "    Top_10Fo=Sort[k2+1-Top:,:]\n",
    "    Top_10Fo=Top_10Fo.astype(int)\n",
    "    return Top_10Fo\n",
    "\n",
    "\n",
    "def M(f):\n",
    "    f_ref=100\n",
    "    return 12*np.log2(f/f_ref)\n",
    "\n",
    "def Thres(a):\n",
    "    if -0.5<a and a<0.5:\n",
    "        t=1\n",
    "    else:\n",
    "        t=0\n",
    "    return t\n",
    "\n",
    "def Angular(a):\n",
    "    x=a-12*int(a/12+0.5)\n",
    "    return x\n",
    "\n",
    "def RawPitch(F_predicted,F_ground):\n",
    "    return Thres(M(F_predicted)-M(F_ground))\n",
    "\n",
    "def ChromaPitch(F_predicted,F_ground):\n",
    "    return Thres(Angular(M(F_predicted)-M(F_ground)))\n",
    "\n",
    "def match(ind,gt,s,frame):\n",
    "    c=0\n",
    "    for p in ind:\n",
    "        fo=fmin*2**(s[p]/B)\n",
    "        if RPA([1],[fo],[gt],1)==100:\n",
    "            c+=1\n",
    "    if c>1:\n",
    "        c=1\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on the dataset....\n",
      "Loaded model from disk\n",
      "0\n",
      "Filename:  daisy1\n",
      "500 500 500\n",
      "0.9781931464174455 0.9813084112149533\n",
      "1\n",
      "Filename:  daisy2\n",
      "500 500 500\n",
      "0.96 0.96\n",
      "2\n",
      "Filename:  pop1\n",
      "500 500 500\n",
      "0.6031390134529148 0.6076233183856502\n",
      "3\n",
      "Filename:  pop2\n",
      "500 500 500\n",
      "0.6313131313131313 0.6515151515151515\n",
      "4\n",
      "Filename:  pop4\n",
      "500 500 500\n",
      "0.7960893854748603 0.7960893854748603\n",
      "5\n",
      "Filename:  pop3\n",
      "500 500 500\n",
      "0.6590389016018307 0.6681922196796338\n",
      "6\n",
      "Filename:  daisy4\n",
      "500 500 500\n",
      "0.9517102615694165 0.9537223340040242\n",
      "0.7970691199756569 0.8026358314677534 0.6625714285714287\n"
     ]
    }
   ],
   "source": [
    "##TESTING ON VARIOUS DATASETS\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.models import model_from_json \n",
    "import mir_eval as mr\n",
    "\n",
    "def custom_activation(x):\n",
    "    return K.l2_normalize(x,axis=1)\n",
    "\n",
    "\n",
    "\n",
    "## Testing on adc2004 dataset\n",
    "\n",
    "print('Testing on the dataset....')\n",
    "# load json and create model\n",
    "json_file = open('./Mir1k-train-adc-test/model_800_eqweight.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json,custom_objects={'custom_activation':custom_activation})\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"./Mir1k-train-adc-test/model.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "data_dirs=\"../../../../../../../Datasets/adc2004/Wavfile\"\n",
    "audio_file = glob(data_dirs + '/*.wav')\n",
    "\n",
    "rpaList=[]\n",
    "rcaList=[]\n",
    "rec_b=[] # Recall before\n",
    "prec_b=[] # Precicion before\n",
    "prec_a=[] # Precision after\n",
    "precis=[] # Precision same as prec_a but estimated from other approach\n",
    "rpamir = []\n",
    "rcamir = []\n",
    "oamir = []\n",
    "for song in range(len(audio_file)):\n",
    "    pathname = os.path.splitext(audio_file[song])[0]\n",
    "    filename = os.path.basename(pathname)\n",
    "    print('Filename: ', filename)\n",
    "    query = audio_file[song]\n",
    "    data_dirp = '../../../../../../../Datasets/adc2004/PitchLabel'\n",
    "    file = data_dirp + '/' + filename + '.txt'\n",
    "    gtv,pitch_labels = np.loadtxt(file)[:,0],np.loadtxt(file)[:,1]\n",
    "   \n",
    "    # path_song=direc_songs+'/'+list_songs[song]\n",
    "    x,fs=lb.load(query,sr=fs,duration=5.0) # Audio\n",
    "    dur = len(x)/fs\n",
    "    gtv = gtv[gtv<dur]\n",
    "    pitch_labels = pitch_labels[:len(gtv)]\n",
    "#     print(len(gtt),len(pl))\n",
    "\n",
    "    CQT = lb.cqt(y=x, sr=fs, fmin=fmin, n_bins=Nf,bins_per_octave=B, hop_length=128)\n",
    "    CQT_mag=np.abs(CQT)\n",
    "    CQT_mag =CQT_mag / np.linalg.norm(CQT_mag)\n",
    "    Nt=CQT_mag.shape[1]\n",
    "\n",
    "    if Nt>len(pitch_labels):\n",
    "        mm = Nt-len(pitch_labels)\n",
    "        Nt = Nt-mm\n",
    "    \n",
    "    v=np.where(pitch_labels>0,1,pitch_labels)\n",
    "    Top_10Peaks=Peak(CQT_mag,Nt)\n",
    "    ww=[]\n",
    "    tot=0\n",
    "    pred_Melody=np.zeros(Nt) \n",
    "    for frame in range(Nt):\n",
    "        feature=[]\n",
    "        s=[]\n",
    "        coun=0\n",
    "        for k in range(Top):\n",
    "                shift=Top_10Peaks[k,frame]\n",
    "                if shift!=0:\n",
    "                    feature.append(np.roll(CQT_mag[:,frame],-shift))\n",
    "                    s.append(shift)\n",
    "        feature=np.array(feature)\n",
    "        coun+=feature.shape[0]\n",
    "        if coun!=0:\n",
    "            s=np.array(s)\n",
    "            y_pred = loaded_model.predict(feature)\n",
    "            pred = list()\n",
    "            for i in range(len(y_pred)):\n",
    "                pred.append(np.argmax(y_pred[i]))\n",
    "           \n",
    "            pred=np.array(pred)\n",
    "            ind=np.where(pred==0)\n",
    "            if len(ind[0])!=0:\n",
    "                if pitch_labels[frame]!=0:\n",
    "                    ww.append(match(ind[0],pitch_labels[frame],s,frame))\n",
    "                ii = np.argmax(y_pred[ind[0],0])\n",
    "                score_ind= ind[0][ii]\n",
    "                pred_Melody[frame]=fmin*2**(s[score_ind]/B)\n",
    "            tot+=coun\n",
    "\n",
    "    rf, ref_voicing = mr.melody.freq_to_voicing(pitch_labels,voicing=None)\n",
    "    ef, est_voicing = mr.melody.freq_to_voicing(pred_Melody,voicing=None)\n",
    "\n",
    "    ref_cent = mr.melody.hz2cents(pitch_labels)\n",
    "    est_cent = mr.melody.hz2cents(pred_Melody)\n",
    "\n",
    "    oa = mr.melody.overall_accuracy(ref_voicing,ref_cent,est_voicing,est_cent,cent_tolerance=50)\n",
    "    rpavv = mr.melody.raw_pitch_accuracy(ref_voicing,ref_cent,est_voicing,est_cent,cent_tolerance=50)\n",
    "    rcavv = mr.melody.raw_chroma_accuracy(ref_voicing,ref_cent,est_voicing,est_cent,cent_tolerance=50)\n",
    "    print(rpavv,rcavv)\n",
    "\n",
    "    rpamir.append(rpavv)\n",
    "    rcamir.append(rcavv)\n",
    "    oamir.append(oa)\n",
    "rpamir = np.array(rpamir)\n",
    "rcamir = np.array(rcamir)\n",
    "oamir = np.array(oamir)\n",
    "print(np.mean(rpamir),np.mean(rcamir),np.mean(oamir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on the dataset....\n",
      "Loaded model from disk\n",
      "0\n",
      "Filename:  train03\n",
      "500 500 500\n",
      "0.7780898876404494 0.7865168539325843\n",
      "1\n",
      "Filename:  train01\n",
      "500 500 500\n",
      "0.9324324324324325 0.9351351351351351\n",
      "2\n",
      "Filename:  train06\n",
      "500 500 500\n",
      "0.6829268292682927 0.7012195121951219\n",
      "3\n",
      "Filename:  train08\n",
      "500 500 500\n",
      "0.9240121580547113 0.9331306990881459\n",
      "4\n",
      "Filename:  train02\n",
      "500 500 500\n",
      "0.9228395061728395 0.9228395061728395\n",
      "5\n",
      "Filename:  train04\n",
      "500 500 500\n",
      "0.7643312101910829 0.821656050955414\n",
      "6\n",
      "Filename:  train09\n",
      "500 500 500\n",
      "0.8557919621749409 0.8581560283687943\n",
      "7\n",
      "Filename:  train07\n",
      "500 500 500\n",
      "0.7522388059701492 0.7582089552238805\n",
      "8\n",
      "Filename:  train10\n",
      "500 500 500\n",
      "1.0 1.0\n",
      "9\n",
      "Filename:  train05\n",
      "500 500 500\n",
      "0.9193083573487032 0.9193083573487032\n",
      "0.8531971149253602 0.8636171098420619 0.5962000000000001\n"
     ]
    }
   ],
   "source": [
    "##TESTING ON VARIOUS DATASETS\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.models import model_from_json \n",
    "import mir_eval as mr\n",
    "\n",
    "def custom_activation(x):\n",
    "    return K.l2_normalize(x,axis=1)\n",
    "\n",
    "\n",
    "\n",
    "## Testing on mirex05 dataset\n",
    "\n",
    "print('Testing on the dataset....')\n",
    "# load json and create model\n",
    "json_file = open('./Mir1k-train-adc-test/model_800_eqweight.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json,custom_objects={'custom_activation':custom_activation})\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"./Mir1k-train-adc-test/model.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "data_dirs=\"../../../../../../../Datasets/mirex05/Wavfile\"\n",
    "audio_file = glob(data_dirs + '/*.wav')\n",
    "\n",
    "rpaList=[]\n",
    "rcaList=[]\n",
    "rec_b=[] # Recall before\n",
    "prec_b=[] # Precicion before\n",
    "prec_a=[] # Precision after\n",
    "precis=[] # Precision same as prec_a but estimated from other approach\n",
    "rpamir = []\n",
    "rcamir = []\n",
    "oamir = []\n",
    "for song in range(len(audio_file)):\n",
    "    pathname = os.path.splitext(audio_file[song])[0]\n",
    "    filename = os.path.basename(pathname)\n",
    "    print('Filename: ', filename)\n",
    "    query = audio_file[song]\n",
    "    data_dirp = '../../../../../../../Datasets/mirex05/PitchLabel'\n",
    "    file = data_dirp + '/' + filename + '.txt'\n",
    "    gtv,pitch_labels = np.loadtxt(file)[:,0],np.loadtxt(file)[:,1]\n",
    "   \n",
    "    x,fs=lb.load(query,sr=fs,duration=5.0) # Audio\n",
    "    dur = len(x)/fs\n",
    "    gtv = gtv[gtv<dur]\n",
    "    pitch_labels = pitch_labels[:len(gtv)]\n",
    "\n",
    "    CQT = lb.cqt(y=x, sr=fs, fmin=fmin, n_bins=Nf,bins_per_octave=B, hop_length=128)\n",
    "    CQT_mag=np.abs(CQT)\n",
    "    CQT_mag =CQT_mag / np.linalg.norm(CQT_mag)\n",
    "    Nt=CQT_mag.shape[1]\n",
    "\n",
    "    if Nt>len(pitch_labels):\n",
    "        mm = Nt-len(pitch_labels)\n",
    "        Nt = Nt-mm\n",
    "    \n",
    "    v=np.where(pitch_labels>0,1,pitch_labels)\n",
    "    Top_10Peaks=Peak(CQT_mag,Nt)\n",
    "    ww=[]\n",
    "    tot=0\n",
    "    pred_Melody=np.zeros(Nt) \n",
    "    for frame in range(Nt):\n",
    "        feature=[]\n",
    "        s=[]\n",
    "        coun=0\n",
    "        for k in range(Top):\n",
    "                shift=Top_10Peaks[k,frame]\n",
    "                if shift!=0:\n",
    "                    feature.append(np.roll(CQT_mag[:,frame],-shift))\n",
    "                    s.append(shift)\n",
    "        feature=np.array(feature)\n",
    "        coun+=feature.shape[0]\n",
    "        if coun!=0:\n",
    "            s=np.array(s)\n",
    "            y_pred = loaded_model.predict(feature)\n",
    "            pred = list()\n",
    "            for i in range(len(y_pred)):\n",
    "                pred.append(np.argmax(y_pred[i]))\n",
    "           \n",
    "            pred=np.array(pred)\n",
    "            ind=np.where(pred==0)\n",
    "            if len(ind[0])!=0:\n",
    "                if pitch_labels[frame]!=0:\n",
    "                    ww.append(match(ind[0],pitch_labels[frame],s,frame))\n",
    "                ii = np.argmax(y_pred[ind[0],0])\n",
    "                score_ind= ind[0][ii]\n",
    "                pred_Melody[frame]=fmin*2**(s[score_ind]/B)\n",
    "            tot+=coun\n",
    "\n",
    "    rf, ref_voicing = mr.melody.freq_to_voicing(pitch_labels,voicing=None)\n",
    "    ef, est_voicing = mr.melody.freq_to_voicing(pred_Melody,voicing=None)\n",
    "\n",
    "    ref_cent = mr.melody.hz2cents(pitch_labels)\n",
    "    est_cent = mr.melody.hz2cents(pred_Melody)\n",
    "\n",
    "    oa = mr.melody.overall_accuracy(ref_voicing,ref_cent,est_voicing,est_cent,cent_tolerance=50)\n",
    "    rpavv = mr.melody.raw_pitch_accuracy(ref_voicing,ref_cent,est_voicing,est_cent,cent_tolerance=50)\n",
    "    rcavv = mr.melody.raw_chroma_accuracy(ref_voicing,ref_cent,est_voicing,est_cent,cent_tolerance=50)\n",
    "    print(rpavv,rcavv)\n",
    "\n",
    "    rpamir.append(rpavv)\n",
    "    rcamir.append(rcavv)\n",
    "    oamir.append(oa)\n",
    "rpamir = np.array(rpamir)\n",
    "rcamir = np.array(rcamir)\n",
    "oamir = np.array(oamir)\n",
    "print(np.mean(rpamir),np.mean(rcamir),np.mean(oamir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on the dataset....\n",
      "Loaded model from disk\n",
      "Filename:  davidson_2_02\n",
      "0.8693333333333333 0.8693333333333333\n",
      "Filename:  ariel_4_07\n",
      "0.8693586698337292 0.8693586698337292\n",
      "Filename:  tammy_1_07\n",
      "0.9433551198257081 0.9520697167755992\n",
      "Filename:  amy_6_04\n",
      "0.8760563380281691 0.8816901408450705\n",
      "Filename:  jmzen_2_06\n",
      "0.8414985590778098 0.8472622478386167\n",
      "Filename:  Ani_1_04\n",
      "0.711864406779661 0.711864406779661\n",
      "Filename:  geniusturtle_4_02\n",
      "0.856492027334852 0.856492027334852\n",
      "Filename:  stool_3_04\n",
      "0.768025078369906 0.768025078369906\n",
      "Filename:  Ani_3_01\n",
      "0.8287937743190662 0.8599221789883269\n",
      "Filename:  bug_3_09\n",
      "0.7984084880636605 0.830238726790451\n",
      "Filename:  amy_16_03\n",
      "0.9122257053291536 0.9122257053291536\n",
      "Filename:  khair_2_01\n",
      "0.653968253968254 0.6571428571428571\n",
      "Filename:  amy_3_07\n",
      "0.8363636363636363 0.8571428571428571\n",
      "Filename:  jmzen_2_10\n",
      "0.8825622775800712 0.896797153024911\n",
      "Filename:  leon_1_09\n",
      "0.7982708933717579 0.8040345821325648\n",
      "Filename:  stool_2_07\n",
      "0.7881619937694704 0.838006230529595\n",
      "Filename:  bobon_4_07\n",
      "0.855036855036855 0.8624078624078624\n",
      "Filename:  bobon_4_06\n",
      "0.8777506112469438 0.8777506112469438\n",
      "Filename:  leon_1_05\n",
      "0.7915492957746478 0.8056338028169014\n",
      "Filename:  annar_1_04\n",
      "0.9184397163120568 0.9184397163120568\n",
      "Filename:  bobon_3_04\n",
      "0.5714285714285714 0.5714285714285714\n",
      "Filename:  amy_14_03\n",
      "0.8619718309859155 0.8873239436619719\n",
      "Filename:  yifen_5_04\n",
      "0.8005780346820809 0.8034682080924855\n",
      "Filename:  abjones_3_11\n",
      "0.6768802228412256 0.6852367688022284\n",
      "Filename:  fdps_1_09\n",
      "0.801007556675063 0.8060453400503779\n",
      "Filename:  titon_5_09\n",
      "0.8857808857808858 0.8857808857808858\n",
      "Filename:  geniusturtle_7_07\n",
      "0.8688524590163934 0.8735362997658079\n",
      "Filename:  heycat_4_01\n",
      "0.913312693498452 0.9597523219814241\n",
      "Filename:  annar_4_01\n",
      "0.9096045197740112 0.9096045197740112\n",
      "Filename:  heycat_5_06\n",
      "0.914572864321608 0.914572864321608\n",
      "Filename:  leon_1_04\n",
      "0.9468599033816425 0.9516908212560387\n",
      "Filename:  Kenshin_5_10\n",
      "0.8617283950617284 0.8617283950617284\n",
      "Filename:  amy_9_07\n",
      "0.7885714285714286 0.7885714285714286\n",
      "Filename:  jmzen_2_04\n",
      "0.8020833333333334 0.8046875\n",
      "Filename:  bobon_2_06\n",
      "0.7975609756097561 0.7975609756097561\n",
      "Filename:  yifen_2_11\n",
      "0.8540772532188842 0.8540772532188842\n",
      "Filename:  annar_2_05\n",
      "0.8910081743869209 0.8910081743869209\n",
      "Filename:  annar_3_05\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-43e1d4bae2e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcoun\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloaded_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[1;32m    129\u001b[0m           method.__name__))\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m   return tf_decorator.make_decorator(\n",
      "\u001b[0;32m~/anaconda3/envs/venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1567\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1568\u001b[0m       \u001b[0;31m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1569\u001b[0;31m       data_handler = data_adapter.DataHandler(\n\u001b[0m\u001b[1;32m   1570\u001b[0m           \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1571\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[1;32m   1103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m     \u001b[0madapter_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1105\u001b[0;31m     self._adapter = adapter_cls(\n\u001b[0m\u001b[1;32m   1106\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0;31m# trigger the next permutation. On the other hand, too many simultaneous\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m     \u001b[0;31m# shuffles can contend on a hardware level and degrade all performance.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m     \u001b[0mindices_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprefetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mslice_batch_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/venv/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, map_func, num_parallel_calls, deterministic)\u001b[0m\n\u001b[1;32m   1693\u001b[0m     \"\"\"\n\u001b[1;32m   1694\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1695\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mMapDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreserve_cardinality\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1696\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m       return ParallelMapDataset(\n",
      "\u001b[0;32m~/anaconda3/envs/venv/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function)\u001b[0m\n\u001b[1;32m   4039\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_use_inter_op_parallelism\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muse_inter_op_parallelism\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4040\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_preserve_cardinality\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreserve_cardinality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4041\u001b[0;31m     self._map_func = StructuredFunctionWrapper(\n\u001b[0m\u001b[1;32m   4042\u001b[0m         \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4043\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/venv/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m   3369\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresource_tracker_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_tracker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3370\u001b[0m         \u001b[0;31m# TODO(b/141462134): Switch to using garbage collection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3371\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_concrete_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3372\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0madd_to_graph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3373\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2936\u001b[0m       \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minputs\u001b[0m \u001b[0mto\u001b[0m \u001b[0mspecialize\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2937\u001b[0m     \"\"\"\n\u001b[0;32m-> 2938\u001b[0;31m     graph_function = self._get_concrete_function_garbage_collected(\n\u001b[0m\u001b[1;32m   2939\u001b[0m         *args, **kwargs)\n\u001b[1;32m   2940\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_garbage_collector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2904\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2905\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2906\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2907\u001b[0m       \u001b[0mseen_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2908\u001b[0m       captured = object_identity.ObjectIdentitySet(\n",
      "\u001b[0;32m~/anaconda3/envs/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3213\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3215\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3063\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3064\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3065\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3066\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3067\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/venv/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    870\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_return_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_return_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mfunc_graph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 872\u001b[0;31m     func_graph = FuncGraph(name, collections=collections,\n\u001b[0m\u001b[1;32m    873\u001b[0m                            capture_by_value=capture_by_value)\n\u001b[1;32m    874\u001b[0m   \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFuncGraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/venv/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, collections, capture_by_value)\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mouter\u001b[0m \u001b[0mgraphs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfailing\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0mto\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m     \"\"\"\n\u001b[0;32m--> 184\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFuncGraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/venv/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2903\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_seed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2904\u001b[0m     \u001b[0;31m# A dictionary of attributes that should be applied to all ops.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2905\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_attr_scope_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2906\u001b[0m     \u001b[0;31m# A map from op type to the kernel label that should be used.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2907\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_op_to_kernel_label_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "##TESTING ON VARIOUS DATASETS\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.models import model_from_json \n",
    "import mir_eval as mr\n",
    "\n",
    "def custom_activation(x):\n",
    "    return K.l2_normalize(x,axis=1)\n",
    "\n",
    "\n",
    "\n",
    "## Testing on mirex05 dataset\n",
    "\n",
    "print('Testing on the dataset....')\n",
    "# load json and create model\n",
    "json_file = open('./Mir1k-train-adc-test/model_800_eqweight.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json,custom_objects={'custom_activation':custom_activation})\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"./Mir1k-train-adc-test/model.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "data_dirs=\"../../../../../../../Datasets/Mir1K/Wavfile\"\n",
    "audio_file = glob(data_dirs + '/*.wav')\n",
    "\n",
    "rpaList=[]\n",
    "rcaList=[]\n",
    "rec_b=[] # Recall before\n",
    "prec_b=[] # Precicion before\n",
    "prec_a=[] # Precision after\n",
    "precis=[] # Precision same as prec_a but estimated from other approach\n",
    "rpamir = []\n",
    "rcamir = []\n",
    "oamir = []\n",
    "\n",
    "for song in range(800,1000):\n",
    "    pathname = os.path.splitext(audio_file[song])[0]\n",
    "    filename = os.path.basename(pathname)\n",
    "    print('Filename: ', filename)\n",
    "    query = audio_file[song]\n",
    "    data_dirp = '../../../../../../../Datasets/Mir1K/PitchLabel'\n",
    "    file = glob(data_dirp + '/' + filename + '.pv')\n",
    "    rf = file[0]\n",
    "    data = open(rf,mode='r')\n",
    "    gtv = np.array([])\n",
    "    pitch_labels = np.array([])\n",
    "    for x in data:\n",
    "        ymm = x.strip().split()\n",
    "        ym = [float(i) for i in ymm]\n",
    "        gtv = np.append(gtv,ym[0])\n",
    "        pitch_labels = np.append(pitch_labels,ym[1])\n",
    "     \n",
    "    x,fs=lb.load(query,sr=fs,duration=5.0) # Audio\n",
    "    dur = len(x)/fs\n",
    "    gtv = gtv[gtv<dur]\n",
    "    pitch_labels = pitch_labels[:len(gtv)]\n",
    "\n",
    "    CQT = lb.cqt(y=x, sr=fs, fmin=fmin, n_bins=Nf,bins_per_octave=B, hop_length=128)\n",
    "    CQT_mag=np.abs(CQT)\n",
    "    CQT_mag =CQT_mag / np.linalg.norm(CQT_mag)\n",
    "    Nt=CQT_mag.shape[1]\n",
    "\n",
    "    if Nt>len(pitch_labels):\n",
    "        mm = Nt-len(pitch_labels)\n",
    "        Nt = Nt-mm\n",
    "    \n",
    "    v=np.where(pitch_labels>0,1,pitch_labels)\n",
    "    Top_10Peaks=Peak(CQT_mag,Nt)\n",
    "    ww=[]\n",
    "    tot=0\n",
    "    pred_Melody=np.zeros(Nt) \n",
    "    for frame in range(Nt):\n",
    "        feature=[]\n",
    "        s=[]\n",
    "        coun=0\n",
    "        for k in range(Top):\n",
    "                shift=Top_10Peaks[k,frame]\n",
    "                if shift!=0:\n",
    "                    feature.append(np.roll(CQT_mag[:,frame],-shift))\n",
    "                    s.append(shift)\n",
    "        feature=np.array(feature)\n",
    "        coun+=feature.shape[0]\n",
    "        if coun!=0:\n",
    "            s=np.array(s)\n",
    "            y_pred = loaded_model.predict(feature)\n",
    "            pred = list()\n",
    "            for i in range(len(y_pred)):\n",
    "                pred.append(np.argmax(y_pred[i]))\n",
    "           \n",
    "            pred=np.array(pred)\n",
    "            ind=np.where(pred==0)\n",
    "            if len(ind[0])!=0:\n",
    "                if pitch_labels[frame]!=0:\n",
    "                    ww.append(match(ind[0],pitch_labels[frame],s,frame))\n",
    "                ii = np.argmax(y_pred[ind[0],0])\n",
    "                score_ind= ind[0][ii]\n",
    "                pred_Melody[frame]=fmin*2**(s[score_ind]/B)\n",
    "            tot+=coun\n",
    "\n",
    "    rf, ref_voicing = mr.melody.freq_to_voicing(pitch_labels,voicing=None)\n",
    "    ef, est_voicing = mr.melody.freq_to_voicing(pred_Melody,voicing=None)\n",
    "\n",
    "    ref_cent = mr.melody.hz2cents(pitch_labels)\n",
    "    est_cent = mr.melody.hz2cents(pred_Melody)\n",
    "\n",
    "    oa = mr.melody.overall_accuracy(ref_voicing,ref_cent,est_voicing,est_cent,cent_tolerance=50)\n",
    "    rpavv = mr.melody.raw_pitch_accuracy(ref_voicing,ref_cent,est_voicing,est_cent,cent_tolerance=50)\n",
    "    rcavv = mr.melody.raw_chroma_accuracy(ref_voicing,ref_cent,est_voicing,est_cent,cent_tolerance=50)\n",
    "    print(rpavv,rcavv)\n",
    "\n",
    "    rpamir.append(rpavv)\n",
    "    rcamir.append(rcavv)\n",
    "    oamir.append(oa)\n",
    "rpamir = np.array(rpamir)\n",
    "rcamir = np.array(rcamir)\n",
    "oamir = np.array(oamir)\n",
    "print(np.mean(rpamir),np.mean(rcamir),np.mean(oamir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
